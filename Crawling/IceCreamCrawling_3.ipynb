{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-23T03:38:11.161712Z",
     "start_time": "2025-10-23T03:38:10.731807Z"
    }
   },
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os  # CSV 저장을 위한 폴더/파일 관리를 위해 import\n",
    "# from selenium import webdriver\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "def clean_filename(filename):\n",
    "    \"\"\"파일 이름으로 사용할 수 없는 문자를 '_'로 대체합니다.\"\"\"\n",
    "    invalid_chars = '\\\\/*?:\"<>|().'\n",
    "    cleaned_name = filename.strip() # 양쪽 공백 제거\n",
    "    for char in invalid_chars:\n",
    "        cleaned_name = cleaned_name.replace(char, '_')\n",
    "    cleaned_name = cleaned_name.replace(' ', '_') # 공백도 '_'로 대체\n",
    "    # 혹시 모를 연속된 '_'를 하나로 변경 (선택적)\n",
    "    while \"__\" in cleaned_name:\n",
    "        cleaned_name = cleaned_name.replace(\"__\", \"_\")\n",
    "    return cleaned_name\n",
    "\n",
    "def scrape_full_preview(driver, wait, scroll_wait):\n",
    "    \"\"\"\n",
    "    [최종 수정됨] StaleElementReferenceException을 방지하기 위해\n",
    "    루프 내에서 tbody를 계속 갱신하고, 파싱 직전에도 갱신합니다.\n",
    "    \"\"\"\n",
    "    print(\"    [Sub] '데이터 미리보기' 탭의 그리드 로드 대기 중...\")\n",
    "    try:\n",
    "        # 그리드 헤더와 본문이 로드될 때까지 대기\n",
    "        wait.until(EC.visibility_of_element_located((By.ID, 'sheet1_Header')))\n",
    "        # 초기 tbody 확인 (이 변수를 루프에서 재사용하지 않음)\n",
    "        initial_tbody = wait.until(EC.visibility_of_element_located((By.ID, 'sheet1_Data')))\n",
    "        print(\"    [Sub] 초기 데이터 로드 완료.\")\n",
    "\n",
    "        if \"데이터 준비중입니다.\" in initial_tbody.text or \"데이터가 없습니다.\" in initial_tbody.text:\n",
    "            print(\"    [Sub] '데이터 준비중'이거나 데이터가 없어 이 항목을 스킵합니다.\")\n",
    "            return None\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"    [Sub] 데이터 그리드(sheet1_Data)를 찾는 데 실패했습니다. (미리보기 미제공 추정)\")\n",
    "        return None\n",
    "\n",
    "    # 1. 헤더(컬럼명) 추출\n",
    "    header_elements = driver.find_elements(By.XPATH, \"//thead[@id='sheet1_Header']//th\")\n",
    "    headers = [h.text for h in header_elements if h.text.strip() not in ['', 'No']]\n",
    "\n",
    "    # 2. 모든 데이터 로드를 위한 스크롤 반복\n",
    "    last_row_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # [수정] 스크롤 전에 매번 tbody를 새로 찾습니다.\n",
    "            tbody = driver.find_element(By.ID, 'sheet1_Data')\n",
    "            current_row_count = len(tbody.find_elements(By.TAG_NAME, 'tr'))\n",
    "\n",
    "            # [수정] 이전 행 개수와 비교하여 더 이상 로드되지 않으면 탈출\n",
    "            if current_row_count == last_row_count:\n",
    "                print(f\"    [Sub] 스크롤 완료. 총 {current_row_count}개 행 로드됨.\")\n",
    "                break\n",
    "\n",
    "            last_row_count = current_row_count\n",
    "            print(f\"      [Sub] 스크롤... 현재 {current_row_count}개 행 로드됨.\")\n",
    "\n",
    "            # JavaScript를 실행하여 tbody의 스크롤을 맨 아래로 내림\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", tbody)\n",
    "\n",
    "            # 스크롤 후 새 행이 로드될 때까지 (행 개수가 늘어날 때까지) 대기\n",
    "            scroll_wait.until(\n",
    "                lambda d: len(d.find_element(By.ID, 'sheet1_Data').find_elements(By.TAG_NAME, 'tr')) > current_row_count\n",
    "            )\n",
    "\n",
    "            time.sleep(0.5) # DOM 안정화를 위한 잠깐의 대기\n",
    "\n",
    "        except TimeoutException:\n",
    "            # 5초 동안 새 행이 로드되지 않으면(TimeoutException 발생)\n",
    "            # 모든 데이터를 로드한 것으로 간주하고 루프 종료\n",
    "            print(f\"    [Sub] 스크롤 시간 초과(정상 종료). 총 {last_row_count}개 행 로드됨.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"    [Sub] 스크롤 중 예외 발생: {e}\")\n",
    "            break # 스크롤 중 다른 오류 발생 시 중지\n",
    "\n",
    "    # 3. 스크롤이 완료된 후, 전체 데이터 파싱\n",
    "    print(\"    [Sub] 전체 데이터 파싱 시작...\")\n",
    "    all_data = []\n",
    "\n",
    "    try:\n",
    "        # [수정] 파싱 직전에도 tbody를 \"반드시\" 새로 찾습니다.\n",
    "        final_tbody = driver.find_element(By.ID, 'sheet1_Data')\n",
    "        data_rows = final_tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "        for row in data_rows:\n",
    "            cells = row.find_elements(By.XPATH, './td[position()>1]')\n",
    "            all_data.append([cell.text for cell in cells])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    [Sub] 최종 데이터 파싱 중 오류 발생: {e}\")\n",
    "        return None # 파싱 실패 시 None 반환\n",
    "\n",
    "    # 4. Pandas DataFrame으로 변환\n",
    "    df = pd.DataFrame(all_data, columns=headers)\n",
    "    return df\n",
    "\n",
    "# --- 메인 크롤링 로직 ---\n",
    "\n",
    "# 크롤링할 URL\n",
    "url = \"https://www.bigdata-environment.kr/user/data_market/detail.do?id=1711a0a0-2f03-11ea-bccd-b704c648ae09\"\n",
    "\n",
    "# 제외할 파일 제목\n",
    "EXCLUDED_TITLE = \"행정동별 제과/아이스크림분야 소비인구\"\n",
    "\n",
    "# CSV 파일이 저장될 디렉토리 이름\n",
    "OUTPUT_DIR = \"scraped_data\"\n",
    "\n",
    "# Chrome WebDriver 설정 (자동 설치)\n",
    "# service = Service(ChromeDriverManager().install())\n",
    "# [수정] Chrome WebDriver 설정 부분\n",
    "# 안정적인 실행을 위해 Chrome 옵션을 추가합니다.\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\") # 샌드박스 모드 비활성화 (권한 충돌 방지)\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\") # 리소스 부족 문제 방지 (주로 Linux/Docker에서 필요하나 Windows에서도 도움됨)\n",
    "chrome_options.add_argument(\"--disable-gpu\") # GPU 가속 비활성화 (GPU 드라이버 충돌 방지)\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\") # 버전은 적당히 최신으로\n",
    "# chrome_options.add_argument(\"--headless\") # (선택사항) 아예 브라우저 창을 띄우지 않고 백그라운드에서 실행\n",
    "\n",
    "print(\"Chrome 드라이버를 옵션과 함께 실행합니다...\")\n",
    "\n",
    "# [수정] 드라이버 설정 시 options=chrome_options 를 전달합니다.\n",
    "# (이전 코드: driver = webdriver.Chrome())\n",
    "# driver = webdriver.Chrome(options=chrome_options)\n",
    "driver = uc.Chrome(options=chrome_options)\n",
    "\n",
    "# 대기 시간 설정\n",
    "wait = WebDriverWait(driver, 10) # 일반 대기 (10초)\n",
    "scroll_wait = WebDriverWait(driver, 5) # 스크롤 후 새 데이터 로드 대기 (5초)\n",
    "\n",
    "# 스크랩한 모든 데이터를 저장할 딕셔너리\n",
    "all_scraped_data = {}\n",
    "\n",
    "print(f\"페이지 로드 중: {url}\")\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # '제공데이터' 목록이 있는 <ul> 요소를 찾습니다.\n",
    "    data_list_container = wait.until(\n",
    "        EC.visibility_of_element_located((By.CSS_SELECTOR, \"div.data-provide-list > ul\"))\n",
    "    )\n",
    "\n",
    "    # <li> 태그(각 파일 항목)의 총 개수를 셉니다.\n",
    "    list_items = data_list_container.find_elements(By.TAG_NAME, \"li\")\n",
    "    item_count = len(list_items)\n",
    "    print(f\"'제공데이터' 섹션에서 총 {item_count}개의 항목을 찾았습니다.\")\n",
    "\n",
    "    # 주의: 0부터 시작 (i = 0은 첫 번째 항목)\n",
    "    for i in range(item_count):\n",
    "        print(f\"\\n--- [Main] 항목 {i+1}/{item_count} 처리 중 ---\")\n",
    "\n",
    "        try:\n",
    "            data_list_container = driver.find_element(By.CSS_SELECTOR, \"div.data-provide-list > ul\")\n",
    "            current_item = data_list_container.find_elements(By.TAG_NAME, \"li\")[i]\n",
    "\n",
    "            title_element = current_item.find_element(By.TAG_NAME, \"dt\")\n",
    "            title = title_element.text.strip()\n",
    "            print(f\"  [Main] 제목: {title}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [Main] {i+1}번째 항목을 찾는 데 실패했습니다: {e}. 다음 항목으로 넘어갑니다.\")\n",
    "            continue\n",
    "\n",
    "        # 1. 제외할 제목인지 확인\n",
    "        if title == EXCLUDED_TITLE:\n",
    "            print(f\"  [Main] 제목이 '{EXCLUDED_TITLE}'와 일치하므로 스킵합니다.\")\n",
    "            continue\n",
    "\n",
    "        # 2. 항목 클릭 (제목(dt)을 클릭하여 해당 파일 선택)\n",
    "        try:\n",
    "            print(f\"  [Main] 항목 클릭: '{title}'\")\n",
    "            title_element.click()\n",
    "\n",
    "            wait.until(\n",
    "                EC.element_to_be_clickable((By.ID, \"IBS_data_preview_Button\"))\n",
    "            )\n",
    "            time.sleep(1) # AJAX 로딩을 위한 추가 대기\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  [Main] 항목 클릭 중 오류 발생: {e}. 이 항목을 스킵합니다.\")\n",
    "            continue\n",
    "\n",
    "        # 3. '데이터 미리보기' 탭 클릭\n",
    "        try:\n",
    "            print(\"  [Main] '데이터 미리보기' 탭 클릭...\")\n",
    "            preview_tab = driver.find_element(By.ID, \"IBS_data_preview_Button\")\n",
    "            preview_tab.click()\n",
    "        except Exception as e:\n",
    "            print(f\"  [Main] '데이터 미리보기' 탭 클릭 중 오류 발생: {e}. 이 항목을 스킵합니다.\")\n",
    "            continue\n",
    "\n",
    "        # 4. 스크롤 및 스크래핑 함수 호출\n",
    "        df = scrape_full_preview(driver, wait, scroll_wait)\n",
    "\n",
    "        if df is not None:\n",
    "            print(f\"  [Main] '{title}' 항목의 데이터 {len(df)}행 스크랩 완료.\")\n",
    "            all_scraped_data[title] = df\n",
    "        else:\n",
    "            print(f\"  [Main] '{title}' 항목에서 데이터를 스크랩하지 못했습니다 (미리보기 없음).\")\n",
    "\n",
    "    # --- 모든 루프 종료 ---\n",
    "    print(\"\\n=========================================\")\n",
    "    print(\"모든 크롤링 작업 완료.\")\n",
    "\n",
    "    if not all_scraped_data:\n",
    "        print(\"스크랩된 데이터가 없습니다. (제외 항목만 있었거나 미리보기가 없는 항목뿐이었습니다.)\")\n",
    "    else:\n",
    "        print(f\"총 {len(all_scraped_data)}개의 파일에서 데이터를 스크랩했습니다.\")\n",
    "\n",
    "        # --- CSV 저장 로직 [추가된 부분] ---\n",
    "\n",
    "        # 출력 디렉토리 생성 (없으면 만들기)\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        print(f\"\\n'{OUTPUT_DIR}' 폴더에 CSV 파일로 저장합니다...\")\n",
    "\n",
    "        for title, df in all_scraped_data.items():\n",
    "            # 파일명으로 부적절한 문자 제거/변경\n",
    "            safe_title = clean_filename(title)\n",
    "            file_path = os.path.join(OUTPUT_DIR, f\"{safe_title}.csv\")\n",
    "\n",
    "            try:\n",
    "                # CSV 파일로 저장 (UTF-8 with BOM으로 Excel 호환성 확보)\n",
    "                df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"  [저장 완료] '{title}' -> {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  [저장 실패] '{title}' 저장 중 오류 발생: {e}\")\n",
    "\n",
    "        print(\"\\n--- 저장 작업 완료 ---\")\n",
    "        # --- CSV 저장 로직 끝 ---\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"전체 프로세스 중 심각한 오류가 발생했습니다: {e}\")\n",
    "\n",
    "finally:\n",
    "    # 모든 작업이 끝나면 브라우저 종료\n",
    "    print(\"브라우저를 닫습니다.\")\n",
    "    driver.quit()"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'undetected_chromedriver'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m  \u001B[38;5;66;03m# CSV 저장을 위한 폴더/파일 관리를 위해 import\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# from selenium import webdriver\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mundetected_chromedriver\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01muc\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mselenium\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mwebdriver\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcommon\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mby\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m By\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mselenium\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mwebdriver\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchrome\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mservice\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Service\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'undetected_chromedriver'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T00:59:39.254260300Z",
     "start_time": "2025-10-24T00:59:22.889128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "# 필수 모듈 임포트\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "def Bigdata_store():\n",
    "    url = \"https://www.bigdata-environment.kr/user/data_market/detail.do?id=1711a0a0-2f03-11ea-bccd-b704c648ae09\"\n",
    "    wd = webdriver.Chrome()\n",
    "    wd.get(url)\n",
    "\n",
    "    wait = WebDriverWait(wd, 10)\n",
    "\n",
    "    try:\n",
    "        # --- 1 ~ 3. (이전과 동일) ---\n",
    "        # (전체보기 클릭 -> 팝업 -> li 클릭 -> 그리드 로드 확인)\n",
    "\n",
    "        # --- (1. '전체보기' 버튼 클릭) ---\n",
    "        xpath_selector = \"//a[@onclick=\\\"modalPop('o','#pop_provide_data')\\\"]\"\n",
    "        view_all_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, xpath_selector))\n",
    "        )\n",
    "        print(\"XPath (onclick)로 '전체보기' 버튼을 찾았습니다. 클릭합니다.\")\n",
    "        wd.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "        print(\"클릭 완료. 팝업 목록을 기다립니다...\")\n",
    "\n",
    "        # --- (2. 팝업 목록에서 li 클릭) ---\n",
    "        # (첫 번째 li를 크롤링한다고 가정 : li:first-child)\n",
    "        li_selector = \"div#pop_provide_data div.provide-data-list ul li:nth-child(3)\"\n",
    "        li_element = wait.until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, li_selector))\n",
    "        )\n",
    "        li_text = li_element.text.replace('\\n', ' ')[:40]\n",
    "        print(f\"팝업의 *세 번째* 항목 '{li_text}...'을(를) 클릭합니다.\")\n",
    "        li_element.click()\n",
    "        print(\"*세 번째* li 클릭 완료. 데이터 미리보기 그리드를 기다립니다...\")\n",
    "\n",
    "        # --- (3. rMateH5 그리드 로드 대기) ---\n",
    "        grid_cell_selector = \"span.rMateH5__DataGridItemRenderer[id^='DataGridItemRenderer']\"\n",
    "        wait.until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, grid_cell_selector))\n",
    "        )\n",
    "        print(\"데이터 그리드 로드를 확인했습니다.\")\n",
    "\n",
    "\n",
    "        # --- 4. 가상 스크롤 처리 (인내심 로직 추가) ---\n",
    "\n",
    "        scroll_container_selector = \"div.rMateH5__VBrowserScrollBar\"\n",
    "        print(f\"'{scroll_container_selector}' 컨테이너를 기준으로 스크롤을 시작합니다.\")\n",
    "\n",
    "        last_scroll_top = -1\n",
    "        all_rows_list = []\n",
    "        seen_rows_set = set()\n",
    "\n",
    "        # [수정] \"인내심\" 카운터 추가\n",
    "        patience_counter = 0\n",
    "\n",
    "        # 헤더/푸터 필터링 목록\n",
    "        HEADER_FOOTER_KEYWORDS = {\n",
    "            \"행정동명\", \"시도명\", \"시군구명\",\"기준일자\",\"성별\",\"성별\",\"연령대\",\"소비인구(명)\",\n",
    "            \"STD_DT\", \"sex_se\", \"year_se\", \"cnsmr_popltn_co\",\n",
    "        }\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # (1. 파싱 로직은 동일)\n",
    "                current_cells = wd.find_elements(By.CSS_SELECTOR, grid_cell_selector)\n",
    "                current_row_data = []\n",
    "\n",
    "                for cell in current_cells:\n",
    "                    try:\n",
    "                        aria_desc = cell.get_attribute(\"aria-describedby\")\n",
    "\n",
    "                        if aria_desc and aria_desc.endswith(\"_Column1\"):\n",
    "                            if current_row_data:\n",
    "                                first_cell_data = str(current_row_data[0]).strip()\n",
    "                                if first_cell_data not in HEADER_FOOTER_KEYWORDS:\n",
    "                                    row_tuple = tuple(current_row_data)\n",
    "                                    if row_tuple not in seen_rows_set:\n",
    "                                        all_rows_list.append(current_row_data)\n",
    "                                        seen_rows_set.add(row_tuple)\n",
    "                                else:\n",
    "                                    print(f\"  (헤더/푸터 행 필터링됨: {first_cell_data}...)\")\n",
    "                            current_row_data = []\n",
    "\n",
    "                        data = cell.get_attribute(\"title\")\n",
    "                        current_row_data.append(data)\n",
    "\n",
    "                    except StaleElementReferenceException:\n",
    "                        continue\n",
    "\n",
    "                if current_row_data:\n",
    "                    first_cell_data = str(current_row_data[0]).strip()\n",
    "                    if first_cell_data not in HEADER_FOOTER_KEYWORDS:\n",
    "                        row_tuple = tuple(current_row_data)\n",
    "                        if row_tuple not in seen_rows_set:\n",
    "                            all_rows_list.append(current_row_data)\n",
    "                            seen_rows_set.add(row_tuple)\n",
    "                    else:\n",
    "                        print(f\"  (헤더/푸터 행 필터링됨: {first_cell_data}...)\")\n",
    "\n",
    "                # (2. 스크롤 로직)\n",
    "                scroll_container = wd.find_element(By.CSS_SELECTOR, scroll_container_selector)\n",
    "                # [수정] 스크롤 속도 조절 (너무 빠르면 로드를 놓칠 수 있음)\n",
    "                wd.execute_script(\"arguments[0].scrollTop += 800\", scroll_container) # 1000 -> 800\n",
    "                time.sleep(0.8) # 1.0 -> 0.8 (조절 가능)\n",
    "\n",
    "                scroll_container = wd.find_element(By.CSS_SELECTOR, scroll_container_selector)\n",
    "                current_scroll_top = wd.execute_script(\"return arguments[0].scrollTop\", scroll_container)\n",
    "\n",
    "                # (3. [핵심 수정] \"인내심\" 체크 로직)\n",
    "                if current_scroll_top == last_scroll_top:\n",
    "                    # 스크롤이 멈췄을 때\n",
    "                    patience_counter += 1\n",
    "                    print(f\"  (스크롤 바닥 도달. 새 데이터 로드 대기... {patience_counter}/3)\")\n",
    "\n",
    "                    # 넉넉하게 3초 대기 (새 네트워크 요청 발생 대기)\n",
    "                    time.sleep(3.0)\n",
    "\n",
    "                    if patience_counter >= 3:\n",
    "                        # 3번(총 9초)을 기다려도 스크롤 위치가 그대로라면,\n",
    "                        # \"진짜\" 데이터의 끝으로 간주하고 종료\n",
    "                        print(\"스크롤 완료. 모든 데이터가 로드되었습니다.\")\n",
    "                        break\n",
    "                else:\n",
    "                    # 스크롤이 성공했다면 (새 데이터가 로드되었거나, 아직 바닥이 아님)\n",
    "                    # \"인내심\" 카운터 초기화\n",
    "                    patience_counter = 0\n",
    "\n",
    "                # (루프가 계속 돌 경우) 현재 위치 저장\n",
    "                last_scroll_top = current_scroll_top\n",
    "                print(f\"새 데이터 로드 중... (현재 스크롤 위치: {current_scroll_top}) (수집된 행: {len(all_rows_list)})\")\n",
    "\n",
    "            except (StaleElementReferenceException, NoSuchElementException) as e:\n",
    "                print(\"  (스크롤바 갱신 감지. 요소를 다시 찾습니다...)\")\n",
    "                time.sleep(0.5)\n",
    "                continue\n",
    "\n",
    "        # --- 5 & 6. (결과 출력 및 CSV 저장 로직 - 이전과 동일) ---\n",
    "        print(\"\\n중복 제거 및 헤더/푸터 필터링 완료.\")\n",
    "\n",
    "        print(\"\\n--- 데이터 크롤링 완료 ---\")\n",
    "\n",
    "        if all_rows_list:\n",
    "            print(f\"총 {len(all_rows_list)}개의 고유한 *데이터 행*을 (순서대로) 추출했습니다.\")\n",
    "\n",
    "            df = pd.DataFrame(all_rows_list)\n",
    "            try:\n",
    "                # (첫 번째 li 데이터라고 가정)\n",
    "                file_name = \"icecream_sales_data(3)_2020/03-2020/10.csv\"\n",
    "\n",
    "                df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "\n",
    "                print(f\"\\n[성공] 데이터가 {file_name} 파일로 저장되었습니다.\")\n",
    "                print(f\" (Python 스크립트와 같은 폴더에 저장됨)\")\n",
    "\n",
    "            except PermissionError:\n",
    "                print(f\"\\n[오류] CSV 파일 저장 실패: {file_name}이(가) 다른 프로그램에서 열려 있습니다.\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n[오류] CSV 파일 저장 중 오류 발생: {e}\")\n",
    "\n",
    "            print(df.head())\n",
    "            print(f\"\\n...\")\n",
    "            print(df.tail())\n",
    "        else:\n",
    "            print(\"추출된 데이터가 없습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"전체 프로세스 중 오류 발생: {e}\")\n",
    "\n",
    "    finally:\n",
    "        print(\"\\n작업 완료. 브라우저를 닫습니다.\")\n",
    "        wd.quit()\n",
    "\n",
    "# 함수 실행\n",
    "if __name__ == \"__main__\":\n",
    "    Bigdata_store()"
   ],
   "id": "b582aab015fddf64",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
